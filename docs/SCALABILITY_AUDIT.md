# AUDITOR√çA DE ESCALABILIDAD FULL-STACK ‚Äî POS-JE
**Fecha:** 2026-02-11  
**Auditor:** Cascade AI ‚Äî Arquitecto Full-Stack Serverless  
**Repositorio:** https://github.com/nicjespinoza/POS-JE  
**Stack:** Next.js 16 + React 18 + TypeScript + Firebase (Firestore, Auth, Hosting)  

---

## RESUMEN EJECUTIVO

| M√©trica | Valor |
|---------|-------|
| **Score de Escalabilidad (0-100)** | **45/100** ‚ö†Ô∏è |
| **Productos soportados sin cambios** | ~500 |
| **Movimientos diarios soportados** | ~200 |
| **Usuarios concurrentes soportados** | ~10 |
| **Cuellos de botella cr√≠ticos** | 6 |
| **Cuellos de botella altos** | 5 |
| **Cuellos de botella medios** | 4 |

**Veredicto:** El proyecto funciona correctamente para un negocio peque√±o (12 productos, 3 sucursales, <5 usuarios). Sin embargo, **NO escala a 1,000+ productos ni a cientos de movimientos diarios** sin cambios estructurales. Los principales problemas son: lecturas completas sin paginaci√≥n, listeners real-time sobre colecciones enteras, y transacciones at√≥micas que hacen N+1 queries internas.

---

## 1. INVENTARIO DE QUERIES FIRESTORE

### 1.1 Mapa Completo de Accesos a Firestore

| # | Archivo | Colecci√≥n | Tipo | Query | Paginaci√≥n | √çndice Requerido | Severidad |
|---|---------|-----------|------|-------|------------|-----------------|-----------|
| Q1 | `DataProvider.tsx:53` | `products` | `onSnapshot` | `collection(db, 'products')` ‚Äî **TODA la colecci√≥n** | ‚ùå NINGUNA | No | üî¥ CR√çTICO |
| Q2 | `DataProvider.tsx:80-89` | `transactions` | `onSnapshot` | `orderBy('date','desc'), limit(50)` √≥ `where('branchId'), orderBy, limit(50)` | ‚úÖ limit(50) | `branchId + date` | ‚úÖ OK |
| Q3 | `contexts/DataContext.tsx:47` | `products` | `onSnapshot` | `collection(db, 'products')` ‚Äî **TODA la colecci√≥n** (duplicada) | ‚ùå NINGUNA | No | üî¥ CR√çTICO |
| Q4 | `contexts/DataContext.tsx:69-78` | `transactions` | `onSnapshot` | Similar a Q2 | ‚úÖ limit(50) | `branchId + date` | ‚úÖ OK |
| Q5 | `inventoryService.ts:46-48` | `inventory` | `onSnapshot` | `where('branchId')` √≥ **TODA la colecci√≥n** (si `branchId='all'`) | ‚ùå NINGUNA | No | üü° ALTO |
| Q6 | `inventoryService.ts:68-79` | `inventory_movements` | `onSnapshot` | `where('branchId'), orderBy('createdAt','desc'), limit(N)` | ‚úÖ limit(N) | `branchId + createdAt` | ‚úÖ OK |
| Q7 | `AdminDashboard.tsx:160` | `inventory` | `onSnapshot` | `getInventoryByBranch('all')` ‚Äî **TODA la colecci√≥n** | ‚ùå NINGUNA | No | üî¥ CR√çTICO |
| Q8 | `AdminDashboard.tsx:164` | `inventory_movements` | `onSnapshot` | `getInventoryMovements('all', 200)` | ‚ö†Ô∏è limit(200) | `createdAt` | üü° ALTO |
| Q9 | `processAtomicSale:430-437` | `inventory_batches` | `getDocs` (dentro de txn) | `where('productId'), where('branchId'), where('remainingStock', '>', 0)` ‚Äî **POR CADA ITEM** | ‚ùå NINGUNA | `productId + branchId + remainingStock` | üî¥ CR√çTICO |
| Q10 | `transferService.ts:53-58` | `inventory_batches` | `getDocs` (dentro de txn) | Misma query que Q9 ‚Äî **POR CADA ITEM** | ‚ùå NINGUNA | `productId + branchId + remainingStock` | üî¥ CR√çTICO |
| Q11 | `reportingService.ts:37-42` | `journal_entries` | `getDocs` | `where('date','>='), where('date','<='), where('status','==')` | ‚ùå NINGUNA | `status + date` | üü° ALTO |
| Q12 | `reportingService.ts:100-107` | `inventory_batches` | `getDocs` | `where('remainingStock', '>', 0)` ¬± `where('branchId')` | ‚ùå NINGUNA | `branchId + remainingStock` | üü° ALTO |
| Q13 | `CartContext.tsx:37-53` | `products` | `onSnapshot` | **UN LISTENER POR ITEM EN CARRITO** ‚Äî `doc(db, 'products', item.id)` | N/A (doc) | No | üü† MEDIO |
| Q14 | `dashboard/page.tsx:33-37` | `orders` | `onSnapshot` | `where('userId'), orderBy('createdAt','desc')` | ‚ùå NINGUNA | `userId + createdAt` | üü† MEDIO |
| Q15 | `portal/page.tsx:61` | `authorized_ips` | `getDocs` | `where('ip', '==', ip)` ‚Äî Una sola vez | ‚úÖ Single | No | ‚úÖ OK |

### 1.2 Resumen de Problemas de Queries

| Problema | Instancias | Impacto |
|----------|-----------|---------|
| **Full-collection reads sin paginaci√≥n** | Q1, Q3, Q5, Q7 | Con 10K productos = 10K reads por cada usuario que abre la app |
| **N+1 queries dentro de transacciones** | Q9, Q10 | Sale con 5 items = 5 queries de batches + 5 transaction.get() cada una |
| **Listeners real-time sobre datos que no cambian frecuentemente** | Q1, Q3, Q7 | Productos no cambian cada segundo, pero onSnapshot dispara reads continuos |
| **√çndices compuestos no definidos** | Q2, Q4, Q6, Q9, Q10, Q11, Q12, Q14 | Sin `firestore.indexes.json`, Firestore genera errores al primer deploy |
| **DataContext duplicado** | Q1 vs Q3, Q2 vs Q4 | Dos providers id√©nticos = doble de reads |

---

## 2. CUELLOS DE BOTELLA POR CAPA

### 2.1 Backend (Firestore)

| # | Cuello de Botella | Ubicaci√≥n | Impacto a Escala | Costo Estimado |
|---|-------------------|-----------|-----------------|----------------|
| B1 | **Products: Full-collection listener** | `DataProvider.tsx:53`, `DataContext.tsx:47` | 10K productos √ó N usuarios √ó cambios = explosi√≥n de reads | 10K reads/apertura √ó $0.06/100K = $0.006/apertura. 1000 aperturas/d√≠a = $6/d√≠a |
| B2 | **Inventory: Full-collection listener con `branchId='all'`** | `AdminDashboard.tsx:160` | Admin dashboard carga TODOS los inventory docs. Con 10K productos √ó 10 branches = 100K docs | 100K reads/apertura admin |
| B3 | **FIFO batch query dentro de transacciones** | `processAtomicSale`, `createStockTransfer` | Query sin √≠ndice + sort en JS. Con 100 batches por producto, cada venta lee todos. | Latencia >2s por venta |
| B4 | **Reporting: Aggregaci√≥n client-side** | `reportingService.ts:30-92` | P&L lee TODOS los journal_entries del rango. 1 a√±o √ó 100 ventas/d√≠a = 36,500 docs le√≠dos para un solo reporte | 36.5K reads/reporte |
| B5 | **Inventory Valuation: Full scan** | `reportingService.ts:99-118` | Lee todos los batches activos (remainingStock > 0). Con 10K productos √ó 3 branches √ó ~5 batches = 150K docs | 150K reads/llamada |
| B6 | **Firestore transaction limit: 500 writes** | `processAtomicSale`, `createStockTransfer` | Una venta de 20 items genera ~60 writes (inventory + movements + batches + transaction + journal). Con 500 limit, m√°ximo ~150 items/transacci√≥n | Hard limit de Firestore |

### 2.2 Frontend (React)

| # | Cuello de Botella | Ubicaci√≥n | Impacto |
|---|-------------------|-----------|---------|
| F1 | **Re-render de TODA la lista de productos** | `DataProvider` ‚Üí `useData()` ‚Üí todos los consumers | Cada cambio en 1 producto re-renderiza todos los componentes que usan `products` |
| F2 | **`createInventorySummary` en cada render** | `AdminDashboard.tsx:171-173` | O(products √ó branches) = 10K √ó 10 = 100K iteraciones en `useMemo`. Con `find()` interno = O(P √ó B √ó I) |
| F3 | **No hay virtualizaci√≥n de listas** | Admin tabla de productos, kardex | Renderiza TODOS los rows del DOM. Con 10K rows = browser lag severo |
| F4 | **CartContext: N listeners simult√°neos** | `CartContext.tsx:37-53` | Cada producto en carrito tiene su propio `onSnapshot`. 20 items = 20 listeners |
| F5 | **Double Context (DataContext + DataProvider)** | `contexts/DataContext.tsx` + `ecommerce/providers/DataProvider.tsx` | Dos copias casi id√©nticas hacen doble de queries a Firestore |

---

## 3. AN√ÅLISIS MULTI-SUCURSAL

### 3.1 Dise√±o Actual

```
inventory/{productId}_{branchId}   ‚Üê Composite ID, flat collection
inventory_movements/{uuid}          ‚Üê Flat, filtered by branchId
inventory_batches/{uuid}            ‚Üê Flat, filtered by productId + branchId
transactions/{uuid}                 ‚Üê Flat, filtered by branchId
```

### 3.2 C√≥mo Escala

| Escenario | Products | Branches | Inventory Docs | Batches (est.) | Movements/d√≠a | Impacto |
|-----------|----------|----------|---------------|----------------|---------------|---------|
| **Actual** | 12 | 3 | 36 | ~36 | ~20 | ‚úÖ Funciona bien |
| **Medio** | 500 | 5 | 2,500 | ~5,000 | ~200 | ‚ö†Ô∏è Admin dashboard lento (2,500 docs en onSnapshot) |
| **Grande** | 2,000 | 10 | 20,000 | ~40,000 | ~500 | üî¥ Full-collection reads = $12/d√≠a solo en reads |
| **Enterprise** | 10,000 | 20 | 200,000 | ~500,000 | ~2,000 | ‚ùå Inutilizable. 200K docs en listener = timeout |

### 3.3 Problemas Espec√≠ficos Multi-Branch

| Problema | Detalle |
|----------|---------|
| **Admin ve TODO** | `getInventoryByBranch('all')` lee toda la colecci√≥n sin filtro. Con 20 sucursales, esto es O(products √ó branches). |
| **Branch isolation solo en queries** | No hay subcolecciones por branch. Todos los docs est√°n en la misma colecci√≥n flat. Firestore no puede indexar eficientemente `branchId` en una colecci√≥n de 200K docs con onSnapshot. |
| **FIFO batches crecen sin l√≠mite** | Cada entrada de mercanc√≠a crea un batch. Nunca se archivan/eliminan. Con 500 entregas √ó 10 branches = 5,000 batches que se escanean en cada venta. |
| **Movements crecen linealmente** | 500 movimientos/d√≠a √ó 365 = 182,500/a√±o. La query `limit(200)` del admin lee las √∫ltimas 200 pero el costo del √≠ndice crece. |

---

## 4. IMPACTO DE CRECIMIENTO ‚Äî PROYECCIONES

### 4.1 Reads de Firestore (costo principal)

| Escenario | Reads/d√≠a (estimado) | Costo/mes (Spark‚ÜíBlaze) |
|-----------|---------------------|------------------------|
| **Actual (12 prod, 3 suc, 3 users)** | ~5,000 | Gratis (50K/d√≠a free) |
| **100 productos, 3 suc, 5 users** | ~15,000 | Gratis |
| **500 productos, 5 suc, 10 users** | ~80,000 | ~$1.50/mes |
| **1,000 productos, 5 suc, 15 users** | ~250,000 | ~$4.50/mes |
| **5,000 productos, 10 suc, 30 users** | ~2,000,000 | ~$36/mes |
| **10,000 productos, 20 suc, 50 users** | ~15,000,000 | ~$270/mes üî¥ |

> **Nota:** Estos costos ASUMEN que se corrigen los full-collection reads. Sin correcci√≥n, los costos se multiplican √ó10.

### 4.2 Writes de Firestore

| Operaci√≥n | Writes Actuales | Con 1K prod + 500 ventas/d√≠a |
|-----------|----------------|------------------------------|
| Venta POS (5 items promedio) | ~15 writes | 500 √ó 15 = 7,500/d√≠a |
| Entrada mercanc√≠a | ~3 writes | ~50 √ó 3 = 150/d√≠a |
| Transferencias | ~10 writes | ~20 √ó 10 = 200/d√≠a |
| **Total writes/d√≠a** | ~100 | **~8,000** |
| **Costo writes/mes** | Gratis | ~$1.50 |

### 4.3 Latencia Esperada

| Operaci√≥n | Actual (12 prod) | 500 prod | 5,000 prod | 10,000 prod |
|-----------|-----------------|----------|-----------|-------------|
| Abrir POS (cargar productos) | <500ms | ~1.5s | ~5s üî¥ | >10s ‚ùå |
| Procesar venta (5 items) | ~800ms | ~1.2s | ~3s üî¥ | ~5s ‚ùå |
| Abrir Admin Dashboard | ~300ms | ~2s | ~8s üî¥ | timeout ‚ùå |
| Generar P&L mensual | ~200ms | ~1s | ~5s | ~15s üî¥ |
| Inventory Valuation | ~100ms | ~500ms | ~3s | ~10s üî¥ |

---

## 5. MEJORAS PROPUESTAS CON C√ìDIGO

### 5.1 [CR√çTICO] Paginaci√≥n de Productos con Cursor

**Estado actual:** `onSnapshot` sobre TODA la colecci√≥n products.

**Mejora:** Paginaci√≥n con cursor-based infinite scroll + b√∫squeda server-side.

```typescript
// ecommerce/services/productService.ts ‚Äî NUEVO
import { db, collection, query, orderBy, limit, startAfter, getDocs, where, onSnapshot, DocumentSnapshot } from '../lib/firebase';
import { Product } from '../lib/types';

const PAGE_SIZE = 50;

export interface ProductPage {
    products: Product[];
    lastDoc: DocumentSnapshot | null;
    hasMore: boolean;
}

/**
 * Paginated product loading (replaces full-collection onSnapshot)
 */
export const getProductsPage = async (
    lastDoc?: DocumentSnapshot | null,
    category?: string,
    searchTerm?: string
): Promise<ProductPage> => {
    let q = query(
        collection(db, 'products'),
        orderBy('name'),
        limit(PAGE_SIZE)
    );

    if (category && category !== 'all') {
        q = query(
            collection(db, 'products'),
            where('category', '==', category),
            orderBy('name'),
            limit(PAGE_SIZE)
        );
    }

    if (lastDoc) {
        q = query(q, startAfter(lastDoc));
    }

    const snapshot = await getDocs(q);
    const products = snapshot.docs.map(doc => ({
        ...doc.data(),
        id: doc.id
    } as Product));

    return {
        products,
        lastDoc: snapshot.docs[snapshot.docs.length - 1] || null,
        hasMore: snapshot.docs.length === PAGE_SIZE
    };
};

/**
 * Real-time listener for a SINGLE page of products (dashboard overview)
 * For POS: load all products of the branch once, cache locally
 */
export const subscribeToProductUpdates = (
    productIds: string[],
    callback: (products: Product[]) => void
) => {
    // Firestore 'in' query supports max 30 items
    // For larger sets, batch into chunks of 30
    const chunks: string[][] = [];
    for (let i = 0; i < productIds.length; i += 30) {
        chunks.push(productIds.slice(i, i + 30));
    }

    const unsubscribes = chunks.map(chunk => {
        const q = query(
            collection(db, 'products'),
            where('__name__', 'in', chunk)
        );
        return onSnapshot(q, (snapshot) => {
            const products = snapshot.docs.map(doc => doc.data() as Product);
            callback(products);
        });
    });

    return () => unsubscribes.forEach(unsub => unsub());
};
```

### 5.2 [CR√çTICO] Inventario: Subcolecciones por Branch

**Estado actual:** Flat collection `inventory/{productId}_{branchId}`.

**Mejora:** Reestructurar para acceso eficiente por branch.

```
ACTUAL (flat):
  inventory/nike-air-max-90_suc-1  { productId, branchId, stock }
  inventory/nike-air-max-90_suc-2  { productId, branchId, stock }
  inventory/nike-air-max-90_suc-3  { productId, branchId, stock }

PROPUESTO (subcolecci√≥n):
  branches/suc-1/inventory/nike-air-max-90  { stock, lowStockThreshold }
  branches/suc-2/inventory/nike-air-max-90  { stock, lowStockThreshold }

  // O alternativamente con Collection Group Queries:
  // Mantener flat pero usar √≠ndices optimizados + paginaci√≥n
```

**Implementaci√≥n pragm√°tica (sin migraci√≥n masiva):**

```typescript
// Mejora: Paginaci√≥n del inventario para Admin
export const getInventoryPaginated = async (
    branchId: string,
    pageSize: number = 100,
    lastDoc?: DocumentSnapshot | null
): Promise<{ items: InventoryItem[]; lastDoc: DocumentSnapshot | null; hasMore: boolean }> => {
    let q;
    
    if (branchId === 'all') {
        q = query(
            collection(db, 'inventory'),
            orderBy('productId'),
            limit(pageSize)
        );
    } else {
        q = query(
            collection(db, 'inventory'),
            where('branchId', '==', branchId),
            orderBy('productId'),
            limit(pageSize)
        );
    }

    if (lastDoc) {
        q = query(q, startAfter(lastDoc));
    }

    const snapshot = await getDocs(q);
    const items = snapshot.docs.map(doc => ({
        ...doc.data(),
        id: doc.id
    } as InventoryItem));

    return {
        items,
        lastDoc: snapshot.docs[snapshot.docs.length - 1] || null,
        hasMore: snapshot.docs.length === pageSize
    };
};
```

### 5.3 [CR√çTICO] FIFO Batch Optimization ‚Äî Batch Index + Archiving

**Problema:** Cada venta hace `getDocs` de TODOS los batches con `remainingStock > 0` para un producto.

**Mejora 1: Composite Index (inmediato)**

```json
// firestore.indexes.json ‚Äî CREAR ESTE ARCHIVO
{
    "indexes": [
        {
            "collectionGroup": "inventory_batches",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "productId", "order": "ASCENDING" },
                { "fieldPath": "branchId", "order": "ASCENDING" },
                { "fieldPath": "remainingStock", "order": "ASCENDING" },
                { "fieldPath": "createdAt", "order": "ASCENDING" }
            ]
        },
        {
            "collectionGroup": "transactions",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "branchId", "order": "ASCENDING" },
                { "fieldPath": "date", "order": "DESCENDING" }
            ]
        },
        {
            "collectionGroup": "inventory_movements",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "branchId", "order": "ASCENDING" },
                { "fieldPath": "createdAt", "order": "DESCENDING" }
            ]
        },
        {
            "collectionGroup": "journal_entries",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "status", "order": "ASCENDING" },
                { "fieldPath": "date", "order": "ASCENDING" }
            ]
        },
        {
            "collectionGroup": "orders",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "userId", "order": "ASCENDING" },
                { "fieldPath": "createdAt", "order": "DESCENDING" }
            ]
        },
        {
            "collectionGroup": "inventory_batches",
            "queryScope": "COLLECTION",
            "fields": [
                { "fieldPath": "branchId", "order": "ASCENDING" },
                { "fieldPath": "remainingStock", "order": "ASCENDING" }
            ]
        }
    ],
    "fieldOverrides": []
}
```

**Mejora 2: Archive depleted batches (Cloud Function)**

```typescript
// functions/src/archiveBatches.ts
// Scheduled Cloud Function: Moves depleted batches to archive
export const archiveDepletedBatches = functions.pubsub
    .schedule('every 24 hours')
    .onRun(async () => {
        const db = admin.firestore();
        const snapshot = await db.collection('inventory_batches')
            .where('remainingStock', '==', 0)
            .limit(500)
            .get();

        const batch = db.batch();
        snapshot.docs.forEach(doc => {
            // Move to archive collection
            batch.set(db.doc(`inventory_batches_archive/${doc.id}`), doc.data());
            batch.delete(doc.ref);
        });

        await batch.commit();
        console.log(`Archived ${snapshot.docs.length} depleted batches`);
    });
```

### 5.4 [ALTO] Reporting: Pre-aggregated Summaries via Cloud Functions

**Problema:** `getProfitAndLoss` lee TODOS los journal entries del rango.

**Mejora:** Cloud Function que mantiene summaries incrementales.

```typescript
// functions/src/onSaleCreated.ts
export const onTransactionCreated = functions.firestore
    .document('journal_entries/{entryId}')
    .onCreate(async (snap, context) => {
        const entry = snap.data() as JournalEntry;
        const db = admin.firestore();
        
        // Extract month key: "2026-02"
        const monthKey = entry.date.substring(0, 7);
        const summaryRef = db.doc(`financial_summaries/${monthKey}_${entry.branchId || 'all'}`);
        
        // Increment counters atomically
        const increments: Record<string, admin.firestore.FieldValue> = {
            transactionCount: admin.firestore.FieldValue.increment(1),
        };

        entry.lines.forEach(line => {
            if (line.accountId.startsWith('4.')) {
                increments.revenue = admin.firestore.FieldValue.increment(line.credit - line.debit);
            } else if (line.accountId === '5.1.01.01') {
                increments.cogs = admin.firestore.FieldValue.increment(line.debit - line.credit);
            } else if (line.accountId.startsWith('5.')) {
                increments.expenses = admin.firestore.FieldValue.increment(line.debit - line.credit);
            }
        });

        await summaryRef.set(increments, { merge: true });
    });

// Client-side: Read single doc instead of scanning entire collection
export const getMonthlyPnL = async (year: number, month: number, branchId?: string): Promise<ReportPnL> => {
    const monthKey = `${year}-${String(month).padStart(2, '0')}`;
    const docId = branchId ? `${monthKey}_${branchId}` : `${monthKey}_all`;
    
    const snap = await getDoc(doc(db, 'financial_summaries', docId));
    const data = snap.data() || { revenue: 0, cogs: 0, expenses: 0 };
    
    return {
        startDate: `${monthKey}-01`,
        endDate: `${monthKey}-31`,
        revenue: data.revenue || 0,
        cogs: data.cogs || 0,
        grossProfit: (data.revenue || 0) - (data.cogs || 0),
        expenses: data.expenses || 0,
        netProfit: (data.revenue || 0) - (data.cogs || 0) - (data.expenses || 0),
        details: { revenueByAccount: {}, expensesByAccount: {} }
    };
};
```

### 5.5 [ALTO] Frontend: Virtualizaci√≥n de Listas + React.memo

```typescript
// Instalar: npm install @tanstack/react-virtual

// Ejemplo: Tabla de productos virtualizada
import { useVirtualizer } from '@tanstack/react-virtual';

const VirtualProductTable: React.FC<{ products: Product[] }> = ({ products }) => {
    const parentRef = React.useRef<HTMLDivElement>(null);

    const virtualizer = useVirtualizer({
        count: products.length,
        getScrollElement: () => parentRef.current,
        estimateSize: () => 60, // row height in px
        overscan: 10,
    });

    return (
        <div ref={parentRef} style={{ height: '600px', overflow: 'auto' }}>
            <div style={{ height: `${virtualizer.getTotalSize()}px`, position: 'relative' }}>
                {virtualizer.getVirtualItems().map(virtualRow => {
                    const product = products[virtualRow.index];
                    return (
                        <div
                            key={product.id}
                            style={{
                                position: 'absolute',
                                top: 0,
                                left: 0,
                                width: '100%',
                                height: `${virtualRow.size}px`,
                                transform: `translateY(${virtualRow.start}px)`,
                            }}
                        >
                            <ProductRow product={product} />
                        </div>
                    );
                })}
            </div>
        </div>
    );
};

// Memoize individual rows to prevent re-renders
const ProductRow = React.memo<{ product: Product }>(({ product }) => (
    <tr className="border-b">
        <td>{product.name}</td>
        <td>{product.category}</td>
        <td>${product.price}</td>
        <td>{product.stock}</td>
    </tr>
));
```

### 5.6 [ALTO] Eliminar DataContext Duplicado

**Problema:** `contexts/DataContext.tsx` y `ecommerce/providers/DataProvider.tsx` son casi id√©nticos ‚Äî ambos leen `products` y `transactions` con `onSnapshot`.

**Soluci√≥n:** Eliminar `contexts/DataContext.tsx` y que el proyecto root use `ecommerce/providers/DataProvider.tsx` como fuente √∫nica.

### 5.7 [MEDIO] Zustand Store con Cache Local (reemplaza Context para productos)

```typescript
// ecommerce/stores/productStore.ts ‚Äî NUEVO
import { create } from 'zustand';
import { persist } from 'zustand/middleware';
import { Product } from '../lib/types';
import { getProductsPage, ProductPage } from '../services/productService';

interface ProductStore {
    products: Product[];
    lastDoc: any;
    hasMore: boolean;
    loading: boolean;
    lastFetched: number;
    
    loadInitial: () => Promise<void>;
    loadMore: () => Promise<void>;
    updateProduct: (product: Product) => void;
    invalidateCache: () => void;
}

const CACHE_TTL = 5 * 60 * 1000; // 5 minutes

export const useProductStore = create<ProductStore>()(
    persist(
        (set, get) => ({
            products: [],
            lastDoc: null,
            hasMore: true,
            loading: false,
            lastFetched: 0,

            loadInitial: async () => {
                const state = get();
                // Skip if cache is fresh
                if (Date.now() - state.lastFetched < CACHE_TTL && state.products.length > 0) {
                    return;
                }

                set({ loading: true });
                const page = await getProductsPage(null);
                set({
                    products: page.products,
                    lastDoc: page.lastDoc,
                    hasMore: page.hasMore,
                    loading: false,
                    lastFetched: Date.now()
                });
            },

            loadMore: async () => {
                const state = get();
                if (!state.hasMore || state.loading) return;

                set({ loading: true });
                const page = await getProductsPage(state.lastDoc);
                set(prev => ({
                    products: [...prev.products, ...page.products],
                    lastDoc: page.lastDoc,
                    hasMore: page.hasMore,
                    loading: false
                }));
            },

            updateProduct: (product) => {
                set(prev => ({
                    products: prev.products.map(p => p.id === product.id ? product : p)
                }));
            },

            invalidateCache: () => {
                set({ lastFetched: 0 });
            }
        }),
        {
            name: 'pos-products-cache',
            partialize: (state) => ({
                products: state.products,
                lastFetched: state.lastFetched
            })
        }
    )
);
```

### 5.8 [MEDIO] Batch Writes para Bulk Operations

**Estado actual:** `handleBulkDelete` y `handleBulkEdit` en AdminDashboard hacen `Promise.all` de N writes individuales.

```typescript
// ACTUAL (N writes paralelas sin control):
const promises = Array.from(selectedIds).map(id => deleteDoc(doc(db, 'transactions', id)));
await Promise.all(promises);

// MEJORADO (Firestore batched writes, max 500):
import { writeBatch } from 'firebase/firestore';

const handleBulkDelete = async () => {
    if (!window.confirm(`¬øEliminar ${selectedIds.size} transacciones?`)) return;
    
    const ids = Array.from(selectedIds);
    
    // Process in chunks of 500 (Firestore batch limit)
    for (let i = 0; i < ids.length; i += 500) {
        const chunk = ids.slice(i, i + 500);
        const batch = writeBatch(db);
        chunk.forEach(id => batch.delete(doc(db, 'transactions', id)));
        await batch.commit();
    }
    
    setSelectedIds(new Set());
};

const handleBulkEdit = async () => {
    const updates: any = {};
    if (bulkEditValues.category) updates.category = bulkEditValues.category;
    if (bulkEditValues.date) updates.date = new Date(bulkEditValues.date).toISOString();
    if (Object.keys(updates).length === 0) return;

    const ids = Array.from(selectedIds);
    
    for (let i = 0; i < ids.length; i += 500) {
        const chunk = ids.slice(i, i + 500);
        const batch = writeBatch(db);
        chunk.forEach(id => batch.update(doc(db, 'transactions', id), updates));
        await batch.commit();
    }
    
    setShowBulkEditModal(false);
    setSelectedIds(new Set());
};
```

---

## 6. COMPARATIVA: ESTADO ACTUAL vs MEJORADO

### 6.1 Reads por Operaci√≥n

| Operaci√≥n | Actual | Mejorado | Reducci√≥n |
|-----------|--------|----------|-----------|
| Abrir POS (cargar productos) | ALL products (10K) | 50 (paginated) | **99.5%** |
| Admin Dashboard | ALL products + ALL inventory + 200 movements | 50 products + 100 inventory (branch) + 50 movements | **95%** |
| Procesar venta (5 items FIFO) | 5 √ó ALL batches del producto (~500 reads) | 5 √ó top-3 batches (indexed, 15 reads) | **97%** |
| P&L mensual | ALL journal_entries del mes (3,000) | 1 doc (pre-aggregated) | **99.97%** |
| Inventory Valuation | ALL active batches (50,000) | 1 doc (pre-aggregated) | **99.998%** |

### 6.2 Latencia Esperada con 5,000 Productos

| Operaci√≥n | Actual | Mejorado |
|-----------|--------|----------|
| Abrir POS | ~5s | <500ms |
| Procesar venta | ~3s | <800ms |
| Admin Dashboard | ~8s | <1.5s |
| P&L mensual | ~5s | <200ms |
| B√∫squeda de producto | Client-side filter (all in memory) | Server-side query + cached |

### 6.3 Costo Mensual (5K productos, 10 sucursales, 30 users)

| Componente | Actual | Mejorado |
|-----------|--------|----------|
| Reads | ~$36/mes | ~$3/mes |
| Writes | ~$2/mes | ~$2/mes (sin cambio) |
| Storage | ~$0.50/mes | ~$0.50/mes |
| **Total** | **~$38.50/mes** | **~$5.50/mes** |

---

## 7. √çNDICES COMPUESTOS REQUERIDOS

No existe `firestore.indexes.json`. Esto es cr√≠tico ‚Äî sin √≠ndices, las queries compuestas fallan en producci√≥n.

| Colecci√≥n | Campos | Orden | Necesario Para |
|-----------|--------|-------|---------------|
| `transactions` | `branchId` ASC, `date` DESC | Composite | DataProvider: transactions por branch |
| `inventory_movements` | `branchId` ASC, `createdAt` DESC | Composite | Kardex por branch |
| `inventory_batches` | `productId` ASC, `branchId` ASC, `remainingStock` ASC | Composite | FIFO en ventas y transferencias |
| `inventory_batches` | `branchId` ASC, `remainingStock` ASC | Composite | Inventory valuation |
| `journal_entries` | `status` ASC, `date` ASC | Composite | P&L reporting |
| `orders` | `userId` ASC, `createdAt` DESC | Composite | Customer dashboard |

---

## 8. PLAN DE IMPLEMENTACI√ìN PRIORIZADO

| Fase | Acci√≥n | Prioridad | Esfuerzo | Impacto |
|------|--------|-----------|----------|---------|
| **Fase 0** | Crear `firestore.indexes.json` con todos los √≠ndices (¬ß5.3) | üî¥ CR√çTICO | 30min | Evita crash en producci√≥n |
| **Fase 0** | Eliminar DataContext duplicado (¬ß5.6) | üî¥ CR√çTICO | 15min | -50% reads inmediato |
| **Fase 1** | Paginaci√≥n de productos en DataProvider (¬ß5.1) | üü° ALTO | 4h | -99% reads en products |
| **Fase 1** | Paginaci√≥n de inventario en Admin (¬ß5.2) | üü° ALTO | 3h | -95% reads en inventory |
| **Fase 1** | Batch writes para bulk operations (¬ß5.8) | üü° ALTO | 1h | Atomic, m√°s r√°pido |
| **Fase 2** | Pre-aggregated financial summaries (¬ß5.4) | üü† MEDIO-ALTO | 6h | -99% reads en reportes |
| **Fase 2** | Archive depleted batches (¬ß5.3 Cloud Function) | üü† MEDIO | 3h | Reduce FIFO scan |
| **Fase 2** | Virtualizaci√≥n de tablas con @tanstack/react-virtual (¬ß5.5) | üü† MEDIO | 3h | Elimina DOM lag |
| **Fase 3** | Zustand store con cache (¬ß5.7) | üîµ MEDIO | 4h | Offline-capable, UX fluida |
| **Fase 3** | Migrar inventario a subcolecciones por branch | üîµ BAJO | 8h+ | Arquitectura √≥ptima long-term |

---

## 9. ARQUITECTURA RECOMENDADA SI SE SUPERAN L√çMITES DE FIRESTORE

Si el proyecto crece m√°s all√° de ~50,000 documentos activos o necesita queries anal√≠ticas complejas:

| Escenario | Soluci√≥n Recomendada |
|-----------|---------------------|
| **>50K productos activos** | Migrar cat√°logo a **Algolia** o **Typesense** para b√∫squeda, mantener Firestore para stock/transacciones |
| **>1M movimientos** | Exportar movimientos hist√≥ricos a **BigQuery** via Firestore Extension, mantener solo √∫ltimos 90 d√≠as en Firestore |
| **Reportes complejos (cross-branch analytics)** | **BigQuery** + **Looker Studio** conectado via Firestore-to-BigQuery extension |
| **>100 usuarios concurrentes** | Considerar **Firebase Realtime Database** para datos de alta-frecuencia (stock real-time) + Firestore para datos transaccionales |
| **Necesidad de SQL/JOINs** | Mantener Firestore para operacional, agregar **Cloud SQL (PostgreSQL)** para analytics via Cloud Functions sync |

---

*Fin del reporte de escalabilidad. La implementaci√≥n de las Fases 0 y 1 es obligatoria antes de superar 500 productos.*
